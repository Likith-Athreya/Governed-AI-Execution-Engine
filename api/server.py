from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import sqlite3
import json
import os

from core.sandbox.sandbox_manager import SandboxManager
from execution.execution_kernel import ExecutionKernel
from agents.nl_interface_agent import NaturalLanguageAgent
from core.audit_logger import log_audit
from core.audit_logger import init_db
from core.audit_logger import DB_PATH
from agents.policy_interpreter_agent import PolicyInterpreterAgent

db_path = DB_PATH


init_db()

app = FastAPI(title="Governed AI Execution Engine")

nl_agent = NaturalLanguageAgent()

SCHEMA = {
    "customers": {
        "id": "INTEGER",
        "name": "TEXT",
        "email": "TEXT",
        "ssn": "TEXT",
        "salary": "INTEGER"
    }
}

POLICY = {
    "max_rows": 100
}

# Active policy can be updated at runtime via /policy/activate
ACTIVE_POLICY = POLICY

# Kernel always reads from the current active policy
kernel = ExecutionKernel(ACTIVE_POLICY)

class NLRequest(BaseModel):
    user_input: str

class SimulateRequest(BaseModel):
    sql: str

class ExecuteRequest(BaseModel):
    sql: str
    simulation: dict
    user_input: str

class PolicyNLRequest(BaseModel):
    policy_text: str

from pydantic import BaseModel

class WhatIfRequest(BaseModel):
    policy: dict
    sql: str

@app.post("/nl_to_sql")
def nl_to_sql(req: NLRequest):
    schema_hint = "customers(id, name, email, ssn, salary)"

    plan = nl_agent.interpret(
        user_input=req.user_input,
        schema_hint=schema_hint
    )

    sql = plan.get("sql")
    if not sql:
        return {
            "status": "error",
            "reason": "No SQL generated by LLM",
            "plan": plan
        }

    return {
        "status": "ok",
        "plan": plan
    }

@app.post("/nl_simulate")
def nl_simulate(req: NLRequest):
    schema_hint = "customers(id, name, email, ssn, salary)"

    plan = nl_agent.interpret(
        user_input=req.user_input,
        schema_hint=schema_hint
    )

    sql = plan.get("sql")
    if not sql:
        return {
            "status": "error",
            "reason": "No SQL generated by LLM",
            "plan": plan
        }

    sandbox = SandboxManager(SCHEMA)
    simulation = sandbox.simulate_query(sql)
    sandbox.teardown()

    return {
        "status": "ok",
        "plan": plan,
        "simulation": simulation
    }

@app.post("/simulate")
def simulate(req: SimulateRequest):
    sandbox = SandboxManager(SCHEMA)
    simulation = sandbox.simulate_query(req.sql)
    sandbox.teardown()

    return {
        "simulation": simulation
    }

@app.post("/execute")
def execute(req: ExecuteRequest):
    try:
        result = kernel.run_sql(req.sql, req.simulation)
        
        status = result.get("status", "UNKNOWN")
        decision = "DENIED" if status == "DENIED" else "ALLOWED"
        reason = result.get("reason", "")
        
        if "governance" in result:
            governance = result["governance"]
            if "decision" in governance:
                gov_decision = governance["decision"].get("decision", "")
                if gov_decision == "DENY":
                    decision = "DENIED"
                elif gov_decision:
                    decision = gov_decision
                reason = governance["decision"].get("explanation", reason)
        elif status == "DENIED" and "reason" in result:
            reason = result["reason"]
        
        log_audit(
            user_input=req.user_input,
            sql=req.sql,
            decision=decision,
            reason=reason,
            simulation=req.simulation
        )
        
        return result
    except Exception as e:
        raise HTTPException(
            status_code= 500, 
            details = str(e)
        )

@app.get("/audit_logs")
def get_audit_logs(limit: int = 50):
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT timestamp, user_input, sql, decision, reason, simulation
            FROM audit_logs
            ORDER BY id DESC
            LIMIT ?
        """, (limit,))

        rows = cursor.fetchall()
        conn.close()

        logs = []
        for row in rows:
            try:
                simulation_data = row[5] if row[5] else "{}"
                try:
                    simulation = json.loads(simulation_data)
                except (json.JSONDecodeError, TypeError):
                    simulation = {}
                
                logs.append({
                    "timestamp": row[0] or "",
                    "user_input": row[1] or "",
                    "sql": row[2] or "",
                    "decision": row[3] or "",
                    "reason": row[4] or "",
                    "simulation": simulation
                })
            except Exception as e:
                continue

        return logs
    except Exception as e:
        return []

@app.post("/policy/interpreter")
def interpret_policy(req: PolicyNLRequest):
    policy = PolicyInterpreterAgent().interpret(req.policy_text)
    return{
        "status": "ok",
        "policy": policy
    }

@app.post("/policy/activate")
def activate_policy(policy: dict):
    global ACTIVE_POLICY
    ACTIVE_POLICY = policy
    # Also update the existing kernel instance so new executions use this policy
    kernel.policy = ACTIVE_POLICY
    return {"status": "activated", "policy": ACTIVE_POLICY}

@app.post("/policy/what_if")
def what_if(req: WhatIfRequest):
    sandbox = SandboxManager(SCHEMA)
    simulation = sandbox.simulate_query(req.sql)
    sandbox.teardown()

    temp_kernel = ExecutionKernel(req.policy)
    decision =temp_kernel.run_sql(req.sql, simulation)

    llm_explanation = PolicyInterpreterAgent().explain_effect(
        policy = req.policy,
        simulation = simulation,
        decision = decision
    )       

    return{
        "simulation": simulation,
        "decision_under_policy": decision["status"],
        "lm_explanation": llm_explanation,
    }

    